{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQzSHk8PlqQ89SjHtKNcPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushiKashyapp/KnowledgeGraphs/blob/main/LNNComputation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computation with **Logical Neural Network**\n",
        "\n",
        "LNN package from IBM allows to define aa neurosymbolic model."
      ],
      "metadata": {
        "id": "uTNYW46CXAgB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CwJaDUBNW-6j"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/IBM/LNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lnn import Model\n",
        "\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "NFHb4rsZXVV_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create the predicates as:\n",
        "\n",
        "smokes(X)\n",
        "\n",
        "cancer(Y)\n",
        "\n",
        "friends(X, Y)"
      ],
      "metadata": {
        "id": "cXBQloIZXbOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lnn import Predicates, World\n",
        "\n",
        "Smokes = Predicates('Smokes')\n",
        "Cancer = Predicates('Cancer', world = World.CLOSED)\n",
        "Friends = Predicates('Friends', arity = 2) # 2 arguments."
      ],
      "metadata": {
        "id": "tBmf4tIiXmci"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable and Axioms"
      ],
      "metadata": {
        "id": "BnQeTnYaYOgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lnn import Variables\n",
        "from lnn import Implies, Iff\n",
        "\n",
        "x, y = Variables('x', 'y')\n",
        "\n",
        "Smoking_causes_Cancer = Implies(Smokes(x), Cancer(x))\n",
        "\n",
        "Smokers_befriend_Smokers = Implies(Friends(x, y), Iff(Smokes(x), Smokes(y)))"
      ],
      "metadata": {
        "id": "sLRiwRRvXxqN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These axioms can be added to the model under open or closed world assumptions."
      ],
      "metadata": {
        "id": "GTys9E7PYxKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lnn import World\n",
        "\n",
        "formulae = [\n",
        "    Smoking_causes_Cancer,\n",
        "    Smokers_befriend_Smokers\n",
        "]\n",
        "model.add_knowledge(*formulae, world = World.AXIOM)"
      ],
      "metadata": {
        "id": "nQa_dujeY6yS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding data to the model."
      ],
      "metadata": {
        "id": "H29QhO0UZV7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lnn import Fact\n",
        "\n",
        "model.add_data({\n",
        "    Friends: {\n",
        "        ('Anna', 'Bob'): Fact.TRUE,\n",
        "        ('Bob', 'Anna'): Fact.TRUE,\n",
        "        ('Anna', 'Edward'): Fact.TRUE,\n",
        "        ('Edward', 'Anna'): Fact.TRUE,\n",
        "        ('Anna', 'Frank'): Fact.TRUE,\n",
        "        ('Frank', 'Anna'): Fact.TRUE,\n",
        "        ('Bob', 'Chris'): Fact.TRUE},\n",
        "    Smokes: {\n",
        "        'Anna': Fact.TRUE,\n",
        "        'Edward': Fact.TRUE,\n",
        "        'Frank': Fact.TRUE,\n",
        "        'Gary': Fact.TRUE},\n",
        "    Cancer: {\n",
        "        'Anna': Fact.TRUE,\n",
        "        'Edward': Fact.TRUE}\n",
        "    })\n",
        "model.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcA0G8gHZY0F",
        "outputId": "a0d99fb5-0d6e-4e06-ab98-8d753fe9655b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***************************************************************************\n",
            "                                LNN Model\n",
            "\n",
            "AXIOM Implies: (Friends(0, 1) → ((Smokes(0) → Smokes(1)) ∧ (Smokes(1) → Smokes(0)))) \n",
            "\n",
            "OPEN Iff: ((Smokes(0) → Smokes(1)) ∧ (Smokes(1) → Smokes(0))) \n",
            "\n",
            "OPEN Implies: (Smokes(0) → Smokes(1)) \n",
            "\n",
            "OPEN Predicate: Friends \n",
            "('Bob', 'Chris')                                            TRUE (1.0, 1.0)\n",
            "('Edward', 'Anna')                                          TRUE (1.0, 1.0)\n",
            "('Anna', 'Frank')                                           TRUE (1.0, 1.0)\n",
            "('Frank', 'Anna')                                           TRUE (1.0, 1.0)\n",
            "('Bob', 'Anna')                                             TRUE (1.0, 1.0)\n",
            "('Anna', 'Edward')                                          TRUE (1.0, 1.0)\n",
            "('Anna', 'Bob')                                             TRUE (1.0, 1.0)\n",
            "\n",
            "AXIOM Implies: (Smokes(0) → Cancer(0)) \n",
            "\n",
            "CLOSED Predicate: Cancer \n",
            "('Edward',)                                                 TRUE (1.0, 1.0)\n",
            "('Anna',)                                                   TRUE (1.0, 1.0)\n",
            "\n",
            "OPEN Predicate: Smokes \n",
            "('Edward',)                                                 TRUE (1.0, 1.0)\n",
            "('Anna',)                                                   TRUE (1.0, 1.0)\n",
            "('Frank',)                                                  TRUE (1.0, 1.0)\n",
            "('Gary',)                                                   TRUE (1.0, 1.0)\n",
            "\n",
            "***************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.infer()\n",
        "model.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3AkNbIjZk0G",
        "outputId": "4b7ece9a-a266-4813-e31d-9386e7a6e266"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***************************************************************************\n",
            "                                LNN Model\n",
            "\n",
            "AXIOM Implies: (Friends(0, 1) → ((Smokes(0) → Smokes(1)) ∧ (Smokes(1) → Smokes(0)))) \n",
            "('Bob', 'Chris')                                            TRUE (1.0, 1.0)\n",
            "('Anna', 'Anna')                                            TRUE (1.0, 1.0)\n",
            "('Frank', 'Anna')                                           TRUE (1.0, 1.0)\n",
            "('Anna', 'Frank')                                           TRUE (1.0, 1.0)\n",
            "('Bob', 'Anna')                                             TRUE (1.0, 1.0)\n",
            "('Gary', 'Frank')                                           TRUE (1.0, 1.0)\n",
            "('Edward', 'Gary')                                          TRUE (1.0, 1.0)\n",
            "('Frank', 'Frank')                                          TRUE (1.0, 1.0)\n",
            "('Gary', 'Anna')                                            TRUE (1.0, 1.0)\n",
            "('Anna', 'Bob')                                             TRUE (1.0, 1.0)\n",
            "('Edward', 'Anna')                                          TRUE (1.0, 1.0)\n",
            "('Edward', 'Frank')                                         TRUE (1.0, 1.0)\n",
            "('Frank', 'Edward')                                         TRUE (1.0, 1.0)\n",
            "('Anna', 'Edward')                                          TRUE (1.0, 1.0)\n",
            "('Gary', 'Edward')                                          TRUE (1.0, 1.0)\n",
            "('Edward', 'Edward')                                        TRUE (1.0, 1.0)\n",
            "('Frank', 'Gary')                                           TRUE (1.0, 1.0)\n",
            "('Anna', 'Gary')                                            TRUE (1.0, 1.0)\n",
            "('Gary', 'Gary')                                            TRUE (1.0, 1.0)\n",
            "\n",
            "OPEN Iff: ((Smokes(0) → Smokes(1)) ∧ (Smokes(1) → Smokes(0))) \n",
            "('Edward', 'Edward')                                        TRUE (1.0, 1.0)\n",
            "('Edward', 'Anna')                                          TRUE (1.0, 1.0)\n",
            "('Anna', 'Anna')                                            TRUE (1.0, 1.0)\n",
            "('Edward', 'Frank')                                         TRUE (1.0, 1.0)\n",
            "('Gary', 'Frank')                                           TRUE (1.0, 1.0)\n",
            "('Anna', 'Frank')                                           TRUE (1.0, 1.0)\n",
            "('Edward', 'Gary')                                          TRUE (1.0, 1.0)\n",
            "('Frank', 'Edward')                                         TRUE (1.0, 1.0)\n",
            "('Anna', 'Edward')                                          TRUE (1.0, 1.0)\n",
            "('Frank', 'Anna')                                           TRUE (1.0, 1.0)\n",
            "('Frank', 'Frank')                                          TRUE (1.0, 1.0)\n",
            "('Frank', 'Gary')                                           TRUE (1.0, 1.0)\n",
            "('Gary', 'Edward')                                          TRUE (1.0, 1.0)\n",
            "('Anna', 'Gary')                                            TRUE (1.0, 1.0)\n",
            "('Gary', 'Gary')                                            TRUE (1.0, 1.0)\n",
            "('Gary', 'Anna')                                            TRUE (1.0, 1.0)\n",
            "('Bob', 'Chris')                                            TRUE (1.0, 1.0)\n",
            "('Bob', 'Anna')                                             TRUE (1.0, 1.0)\n",
            "('Anna', 'Bob')                                             TRUE (1.0, 1.0)\n",
            "\n",
            "OPEN Implies: (Smokes(0) → Smokes(1)) \n",
            "('Gary', 'Frank')                                           TRUE (1.0, 1.0)\n",
            "('Edward', 'Edward')                                        TRUE (1.0, 1.0)\n",
            "('Edward', 'Anna')                                          TRUE (1.0, 1.0)\n",
            "('Edward', 'Frank')                                         TRUE (1.0, 1.0)\n",
            "('Anna', 'Anna')                                            TRUE (1.0, 1.0)\n",
            "('Anna', 'Frank')                                           TRUE (1.0, 1.0)\n",
            "('Edward', 'Gary')                                          TRUE (1.0, 1.0)\n",
            "('Frank', 'Edward')                                         TRUE (1.0, 1.0)\n",
            "('Anna', 'Edward')                                          TRUE (1.0, 1.0)\n",
            "('Frank', 'Anna')                                           TRUE (1.0, 1.0)\n",
            "('Frank', 'Frank')                                          TRUE (1.0, 1.0)\n",
            "('Frank', 'Gary')                                           TRUE (1.0, 1.0)\n",
            "('Gary', 'Edward')                                          TRUE (1.0, 1.0)\n",
            "('Anna', 'Gary')                                            TRUE (1.0, 1.0)\n",
            "('Gary', 'Anna')                                            TRUE (1.0, 1.0)\n",
            "('Gary', 'Gary')                                            TRUE (1.0, 1.0)\n",
            "\n",
            "OPEN Predicate: Friends \n",
            "('Bob', 'Chris')                                            TRUE (1.0, 1.0)\n",
            "('Edward', 'Anna')                                          TRUE (1.0, 1.0)\n",
            "('Anna', 'Frank')                                           TRUE (1.0, 1.0)\n",
            "('Frank', 'Anna')                                           TRUE (1.0, 1.0)\n",
            "('Bob', 'Anna')                                             TRUE (1.0, 1.0)\n",
            "('Anna', 'Edward')                                          TRUE (1.0, 1.0)\n",
            "('Anna', 'Bob')                                             TRUE (1.0, 1.0)\n",
            "('Edward', 'Edward')                                     UNKNOWN (0.0, 1.0)\n",
            "('Anna', 'Anna')                                         UNKNOWN (0.0, 1.0)\n",
            "('Edward', 'Frank')                                      UNKNOWN (0.0, 1.0)\n",
            "('Frank', 'Frank')                                       UNKNOWN (0.0, 1.0)\n",
            "('Gary', 'Frank')                                        UNKNOWN (0.0, 1.0)\n",
            "('Edward', 'Gary')                                       UNKNOWN (0.0, 1.0)\n",
            "('Gary', 'Anna')                                         UNKNOWN (0.0, 1.0)\n",
            "('Frank', 'Edward')                                      UNKNOWN (0.0, 1.0)\n",
            "('Frank', 'Gary')                                        UNKNOWN (0.0, 1.0)\n",
            "('Gary', 'Edward')                                       UNKNOWN (0.0, 1.0)\n",
            "('Anna', 'Gary')                                         UNKNOWN (0.0, 1.0)\n",
            "('Gary', 'Gary')                                         UNKNOWN (0.0, 1.0)\n",
            "\n",
            "AXIOM Implies: (Smokes(0) → Cancer(0)) \n",
            "('Edward',)                                                 TRUE (1.0, 1.0)\n",
            "('Anna',)                                                   TRUE (1.0, 1.0)\n",
            "('Frank',)                                         CONTRADICTION (1.0, 0.0)\n",
            "('Gary',)                                          CONTRADICTION (1.0, 0.0)\n",
            "\n",
            "CLOSED Predicate: Cancer \n",
            "('Edward',)                                                 TRUE (1.0, 1.0)\n",
            "('Anna',)                                                   TRUE (1.0, 1.0)\n",
            "('Frank',)                                                 FALSE (0.0, 0.0)\n",
            "('Gary',)                                                  FALSE (0.0, 0.0)\n",
            "\n",
            "OPEN Predicate: Smokes \n",
            "('Edward',)                                                 TRUE (1.0, 1.0)\n",
            "('Anna',)                                                   TRUE (1.0, 1.0)\n",
            "('Frank',)                                                  TRUE (1.0, 1.0)\n",
            "('Gary',)                                                   TRUE (1.0, 1.0)\n",
            "\n",
            "***************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepProbLog\n",
        "\n",
        "DeepProbLog is another framework for neurosymbolic reasoning, it can be used to learn sums of digits from the MNIST dataset."
      ],
      "metadata": {
        "id": "xKts7P6HZq0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install deepproblog\n",
        "!wget https://github.com/ML-KULeuven/deepproblog/raw/master/src/deepproblog/examples/minimal/addition.pl"
      ],
      "metadata": {
        "id": "CfmY-0NUf6zS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the MNIST dataset"
      ],
      "metadata": {
        "id": "5rcsJQytZ9IE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Mapping, Iterator\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from problog.logic import Term, Constant\n",
        "\n",
        "from deepproblog.dataset import Dataset\n",
        "from deepproblog.query import Query\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "\n",
        "datasets = {\n",
        "    \"train\": torchvision.datasets.MNIST(\n",
        "        root='data/', train=True, download=True, transform=transform\n",
        "    ),\n",
        "    \"test\": torchvision.datasets.MNIST(\n",
        "        root='data/', train=False, download=True, transform=transform\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "class MNISTImages(Mapping[Term, torch.Tensor]):\n",
        "\n",
        "    def __iter__(self) -> Iterator:\n",
        "        for i in range(self.dataset):\n",
        "            yield self.dataset[i][0]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __init__(self, subset):\n",
        "        self.subset = subset\n",
        "        self.dataset = datasets[self.subset]\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.dataset[int(item[0])][0]\n",
        "\n",
        "\n",
        "class AdditionDataset(Dataset):\n",
        "\n",
        "    def __init__(self, subset):\n",
        "        self.subset = subset\n",
        "        self.dataset = datasets[subset]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset) // 2\n",
        "\n",
        "    def to_query(self, i: int) -> Query:\n",
        "        image1 = Term(\"tensor\", Term(self.subset, Constant(i * 2)))\n",
        "        image2 = Term(\"tensor\", Term(self.subset, Constant(i * 2 + 1)))\n",
        "        label = Constant(int(self.dataset[i*2][1] + self.dataset[i*2+1][1]))\n",
        "        term = Term('addition', image1, image2, label)\n",
        "        return Query(term)\n",
        "\n",
        "dataset = AdditionDataset(\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn870RPugDJn",
        "outputId": "08083283-8ff5-4066-cd6e-07915551d194"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 35760207.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1121170.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 10074293.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3332842.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting MNIST data to images."
      ],
      "metadata": {
        "id": "d2IDOizEcakj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "transform = T.ToPILImage()\n",
        "transform(dataset.dataset[2][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "DQ_cYh7LbO-_",
        "outputId": "8e113347-9fd7-44c8-ab66-ef624bddccf8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA30lEQVR4nGNkZMANmPDI0VWy/YIfQrJmMapk1gwog5GRkfGfOyMyYDVeGsjIyMjIyMDIyMi4E1XS/K8rhMHEwMDAwIJqqgXDdoSDYvRQJeUYShF2fvqLYqz++b/WjHA77f9+QpZ0/7tREclOhmlwI2XWpqxiYH+AHAgqDAwMcUkvFXQenVJn+vRnJgPCTt3ft+fPn//779eHvfI7LLkvf0VYwcDA8L6YgYGBIXn1BAYGBoaz+ns8kHSiguC/wjAmtoBPgDFIjTImbzyS/1jwSDIU4jMWj535/+BMRtokagAowDLzqctdUwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform(dataset.dataset[3][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "B4zwf79ecs53",
        "outputId": "4579e6c3-ddf9-40bc-e5dc-49b09b32425f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAvElEQVR4nGNkZMANmPDI0VHy569/dbgkD77/8+cfhMmCIWn3HcFmRANdN78vtxeEsNElK09+/74PxkGXNP/9uxrOQbNT48ifB9w47HSc/fv7PwQXVfLS99+F8gguij8X8jN07HvEgNVYx9+/f9sjG4TsoHd/GBgEUNyHUJe4+/v3SBQnIEle/f69UxJFEslBagwM2i8YsBtr/x/NOUjGJp78/V5SEFUS7lpFPYZTaIYSmUzW92BKMtImUQMAPpI4Z3KoTqYAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_query(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btL8vVTDcxjC",
        "outputId": "aaac58a5-4d76-43dc-cb79-261e4d79cdb8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0::addition(tensor(train(2)),tensor(train(3)),5), {})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a neural network to solve MNIST"
      ],
      "metadata": {
        "id": "xnWjDRjkc4J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, 5),\n",
        "            nn.MaxPool2d(2, 2),  # 6 24 24 -> 6 12 12\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(6, 16, 5),  # 6 12 12 -> 16 8 8\n",
        "            nn.MaxPool2d(2, 2),  # 16 8 8 -> 16 4 4\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16 * 4 * 4, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 10),\n",
        "            nn.Softmax(1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "wKnNU9yJg_ng"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "TKOMYfcAdy7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from deepproblog.dataset import DataLoader\n",
        "from deepproblog.engines import ExactEngine\n",
        "from deepproblog.model import Model\n",
        "from deepproblog.network import Network\n",
        "from deepproblog.train import train_model\n",
        "\n",
        "network = MNIST_Net()\n",
        "net = Network(network, \"mnist_net\", batching=True)\n",
        "net.optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
        "\n",
        "model = Model(\"addition.pl\", [net])\n",
        "model.set_engine(ExactEngine(model))\n",
        "model.add_tensor_source(\"train\", MNISTImages(\"train\"))\n",
        "model.add_tensor_source(\"test\", MNISTImages(\"test\"))\n",
        "\n",
        "dataset = AdditionDataset(\"train\")\n",
        "\n",
        "# Train the model\n",
        "loader = DataLoader(dataset, 2, False)\n",
        "train_model(model, loader, 1, log_iter=100, profile=0)\n",
        "model.save_state(\"snapshot/trained_model.pth\")\n",
        "\n",
        "# Query the model\n",
        "query = dataset.to_query(0)\n",
        "print(query)\n",
        "result = model.solve([query])[0]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "3A2DiYE7hCQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74118a3-638c-49fb-9368-e2ad88ba7377"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deepproblog/engines/__init__.py:6: UserWarning: ApproximateEngine is not available as PySwip could not be found\n",
            "  warnings.warn(\"ApproximateEngine is not available as PySwip could not be found\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training  for 1 epoch(s)\n",
            "Epoch 1\n",
            "Iteration:  100 \ts:12.3677 \tAverage Loss:  2.762265934944153\n",
            "Iteration:  200 \ts:12.9491 \tAverage Loss:  2.7005186969041826\n",
            "Iteration:  300 \ts:12.3854 \tAverage Loss:  2.4862266620993614\n",
            "Iteration:  400 \ts:13.6648 \tAverage Loss:  2.0800369179248808\n",
            "Iteration:  500 \ts:12.9458 \tAverage Loss:  1.2904680143034784\n",
            "Iteration:  600 \ts:13.7440 \tAverage Loss:  0.8459320670925081\n",
            "Iteration:  700 \ts:12.1735 \tAverage Loss:  0.9239749544451479\n",
            "Iteration:  800 \ts:12.8871 \tAverage Loss:  0.5996868947453913\n",
            "Iteration:  900 \ts:13.0257 \tAverage Loss:  0.59107800071768\n",
            "Iteration:  1000 \ts:13.0264 \tAverage Loss:  0.47710468759207286\n",
            "Iteration:  1100 \ts:12.0098 \tAverage Loss:  0.5075771557187545\n",
            "Iteration:  1200 \ts:11.9928 \tAverage Loss:  0.459920847316389\n",
            "Iteration:  1300 \ts:12.7151 \tAverage Loss:  0.3836900119949678\n",
            "Iteration:  1400 \ts:11.9159 \tAverage Loss:  0.41574702696923355\n",
            "Iteration:  1500 \ts:12.1045 \tAverage Loss:  0.39746683034129093\n",
            "Iteration:  1600 \ts:12.5280 \tAverage Loss:  0.25238476027792783\n",
            "Iteration:  1700 \ts:11.5607 \tAverage Loss:  0.29923542506102874\n",
            "Iteration:  1800 \ts:12.1912 \tAverage Loss:  0.42900556767373926\n",
            "Iteration:  1900 \ts:12.5872 \tAverage Loss:  0.37644046505129564\n",
            "Iteration:  2000 \ts:12.0060 \tAverage Loss:  0.4311697745557103\n",
            "Iteration:  2100 \ts:12.7229 \tAverage Loss:  0.3704564313058381\n",
            "Iteration:  2200 \ts:11.8241 \tAverage Loss:  0.3980699954251486\n",
            "Iteration:  2300 \ts:12.1300 \tAverage Loss:  0.2995928769854936\n",
            "Iteration:  2400 \ts:12.7071 \tAverage Loss:  0.3868155521088647\n",
            "Iteration:  2500 \ts:11.7559 \tAverage Loss:  0.1961426489652049\n",
            "Iteration:  2600 \ts:11.7600 \tAverage Loss:  0.2822381742556809\n",
            "Iteration:  2700 \ts:12.3422 \tAverage Loss:  0.1393306673983252\n",
            "Iteration:  2800 \ts:11.8911 \tAverage Loss:  0.35169155302316446\n",
            "Iteration:  2900 \ts:12.0470 \tAverage Loss:  0.31939457079250133\n",
            "Iteration:  3000 \ts:12.6845 \tAverage Loss:  0.3616606361051163\n",
            "Iteration:  3100 \ts:11.1592 \tAverage Loss:  0.2179372793222724\n",
            "Iteration:  3200 \ts:12.1692 \tAverage Loss:  0.2529428309265054\n",
            "Iteration:  3300 \ts:13.1311 \tAverage Loss:  0.38570534903297315\n",
            "Iteration:  3400 \ts:12.2415 \tAverage Loss:  0.19175427787003912\n",
            "Iteration:  3500 \ts:13.0500 \tAverage Loss:  0.24809746558928603\n",
            "Iteration:  3600 \ts:14.0890 \tAverage Loss:  0.2870595461431321\n",
            "Iteration:  3700 \ts:11.9056 \tAverage Loss:  0.2663849665691032\n",
            "Iteration:  3800 \ts:11.7267 \tAverage Loss:  0.19942764677404692\n",
            "Iteration:  3900 \ts:12.7812 \tAverage Loss:  0.3015809652338462\n",
            "Iteration:  4000 \ts:12.0849 \tAverage Loss:  0.34687760479559077\n",
            "Iteration:  4100 \ts:12.7139 \tAverage Loss:  0.2190933943809241\n",
            "Iteration:  4200 \ts:11.7589 \tAverage Loss:  0.21591706867427454\n",
            "Iteration:  4300 \ts:11.9227 \tAverage Loss:  0.260316593678398\n",
            "Iteration:  4400 \ts:12.4967 \tAverage Loss:  0.3111516950286389\n",
            "Iteration:  4500 \ts:11.8854 \tAverage Loss:  0.26347701689234326\n",
            "Iteration:  4600 \ts:11.4730 \tAverage Loss:  0.20759714641037544\n",
            "Iteration:  4700 \ts:12.1243 \tAverage Loss:  0.13400076478722758\n",
            "Iteration:  4800 \ts:11.5375 \tAverage Loss:  0.18341326146891695\n",
            "Iteration:  4900 \ts:11.9317 \tAverage Loss:  0.2096574337873774\n",
            "Iteration:  5000 \ts:12.5280 \tAverage Loss:  0.10971353058918186\n",
            "Iteration:  5100 \ts:11.9790 \tAverage Loss:  0.30311079136351565\n",
            "Iteration:  5200 \ts:11.8527 \tAverage Loss:  0.225359973312801\n",
            "Iteration:  5300 \ts:13.1231 \tAverage Loss:  0.22104112716381633\n",
            "Iteration:  5400 \ts:12.0973 \tAverage Loss:  0.16561444128350739\n",
            "Iteration:  5500 \ts:12.0939 \tAverage Loss:  0.13993307787519937\n",
            "Iteration:  5600 \ts:12.8773 \tAverage Loss:  0.1850460476051494\n",
            "Iteration:  5700 \ts:11.8614 \tAverage Loss:  0.27679754418321695\n",
            "Iteration:  5800 \ts:12.0152 \tAverage Loss:  0.16051719332822365\n",
            "Iteration:  5900 \ts:12.4650 \tAverage Loss:  0.1079462787769313\n",
            "Iteration:  6000 \ts:11.2398 \tAverage Loss:  0.24130878526188396\n",
            "Iteration:  6100 \ts:11.2953 \tAverage Loss:  0.12763139947304306\n",
            "Iteration:  6200 \ts:12.8028 \tAverage Loss:  0.24513332174614696\n",
            "Iteration:  6300 \ts:12.5669 \tAverage Loss:  0.2360817915182134\n",
            "Iteration:  6400 \ts:12.1714 \tAverage Loss:  0.211136904761699\n",
            "Iteration:  6500 \ts:12.8827 \tAverage Loss:  0.23654964493730765\n",
            "Iteration:  6600 \ts:11.9320 \tAverage Loss:  0.08394530870474819\n",
            "Iteration:  6700 \ts:12.1739 \tAverage Loss:  0.39226344217853254\n",
            "Iteration:  6800 \ts:12.0706 \tAverage Loss:  0.2160688413864814\n",
            "Iteration:  6900 \ts:12.5520 \tAverage Loss:  0.16002335818050578\n",
            "Iteration:  7000 \ts:11.6540 \tAverage Loss:  0.08795413935158677\n",
            "Iteration:  7100 \ts:11.4336 \tAverage Loss:  0.2446063645274982\n",
            "Iteration:  7200 \ts:12.7130 \tAverage Loss:  0.2953177667859059\n",
            "Iteration:  7300 \ts:11.7425 \tAverage Loss:  0.16997933998479767\n",
            "Iteration:  7400 \ts:11.4113 \tAverage Loss:  0.14895235786465444\n",
            "Iteration:  7500 \ts:12.7656 \tAverage Loss:  0.14622811918470824\n",
            "Iteration:  7600 \ts:11.7640 \tAverage Loss:  0.11540691091569492\n",
            "Iteration:  7700 \ts:11.8823 \tAverage Loss:  0.22807100936198765\n",
            "Iteration:  7800 \ts:12.5389 \tAverage Loss:  0.12766398159396455\n",
            "Iteration:  7900 \ts:11.9940 \tAverage Loss:  0.20823693697382167\n",
            "Iteration:  8000 \ts:11.9102 \tAverage Loss:  0.22015990079817413\n",
            "Iteration:  8100 \ts:12.4481 \tAverage Loss:  0.22756752983787712\n",
            "Iteration:  8200 \ts:11.9049 \tAverage Loss:  0.15570681340368558\n",
            "Iteration:  8300 \ts:11.8247 \tAverage Loss:  0.1146668051788247\n",
            "Iteration:  8400 \ts:12.6032 \tAverage Loss:  0.13569410160116707\n",
            "Iteration:  8500 \ts:12.7047 \tAverage Loss:  0.16547283466490117\n",
            "Iteration:  8600 \ts:13.7180 \tAverage Loss:  0.11793538324606195\n",
            "Iteration:  8700 \ts:12.8094 \tAverage Loss:  0.28346170871334225\n",
            "Iteration:  8800 \ts:11.8431 \tAverage Loss:  0.19495665872644483\n",
            "Iteration:  8900 \ts:11.5062 \tAverage Loss:  0.1702119934319788\n",
            "Iteration:  9000 \ts:12.7188 \tAverage Loss:  0.19521501985255602\n",
            "Iteration:  9100 \ts:11.7505 \tAverage Loss:  0.19961353565458417\n",
            "Iteration:  9200 \ts:12.0183 \tAverage Loss:  0.16689018999268274\n",
            "Iteration:  9300 \ts:12.0584 \tAverage Loss:  0.22898319858855756\n",
            "Iteration:  9400 \ts:12.9543 \tAverage Loss:  0.12534437290580988\n",
            "Iteration:  9500 \ts:11.8976 \tAverage Loss:  0.2456506909763653\n",
            "Iteration:  9600 \ts:11.8064 \tAverage Loss:  0.13397948104913876\n",
            "Iteration:  9700 \ts:12.7436 \tAverage Loss:  0.2466216260073913\n",
            "Iteration:  9800 \ts:12.0555 \tAverage Loss:  0.13604921503993828\n",
            "Iteration:  9900 \ts:12.1769 \tAverage Loss:  0.2585686969053464\n",
            "Iteration:  10000 \ts:12.8124 \tAverage Loss:  0.2231269466905615\n",
            "Iteration:  10100 \ts:11.8149 \tAverage Loss:  0.14910559380175342\n",
            "Iteration:  10200 \ts:11.5479 \tAverage Loss:  0.0887313259954421\n",
            "Iteration:  10300 \ts:12.6018 \tAverage Loss:  0.2517120269710043\n",
            "Iteration:  10400 \ts:11.5274 \tAverage Loss:  0.23631308617905233\n",
            "Iteration:  10500 \ts:11.9842 \tAverage Loss:  0.16004381029208253\n",
            "Iteration:  10600 \ts:11.8632 \tAverage Loss:  0.2990966693873579\n",
            "Iteration:  10700 \ts:12.4716 \tAverage Loss:  0.2664797764141063\n",
            "Iteration:  10800 \ts:12.0194 \tAverage Loss:  0.2352579649508299\n",
            "Iteration:  10900 \ts:11.7513 \tAverage Loss:  0.1630202964620753\n",
            "Iteration:  11000 \ts:12.5865 \tAverage Loss:  0.2240355601089703\n",
            "Iteration:  11100 \ts:11.7211 \tAverage Loss:  0.1383546515423481\n",
            "Iteration:  11200 \ts:11.8193 \tAverage Loss:  0.1164354625942867\n",
            "Iteration:  11300 \ts:12.4605 \tAverage Loss:  0.14499362334700605\n",
            "Iteration:  11400 \ts:11.5921 \tAverage Loss:  0.14279016919528886\n",
            "Iteration:  11500 \ts:11.2384 \tAverage Loss:  0.12754698954226934\n",
            "Iteration:  11600 \ts:11.0983 \tAverage Loss:  0.24786582736034307\n",
            "Iteration:  11700 \ts:12.5260 \tAverage Loss:  0.11859201461237978\n",
            "Iteration:  11800 \ts:11.8338 \tAverage Loss:  0.11176415596599973\n",
            "Iteration:  11900 \ts:11.8392 \tAverage Loss:  0.23610158514907117\n",
            "Iteration:  12000 \ts:12.6077 \tAverage Loss:  0.1631838641242607\n",
            "Iteration:  12100 \ts:11.7823 \tAverage Loss:  0.12954773536092712\n",
            "Iteration:  12200 \ts:11.5887 \tAverage Loss:  0.06121090291293301\n",
            "Iteration:  12300 \ts:12.6760 \tAverage Loss:  0.3247713256408968\n",
            "Iteration:  12400 \ts:11.7986 \tAverage Loss:  0.3319418247002052\n",
            "Iteration:  12500 \ts:12.5172 \tAverage Loss:  0.09230752868614775\n",
            "Iteration:  12600 \ts:11.0125 \tAverage Loss:  0.17154048449437898\n",
            "Iteration:  12700 \ts:12.4071 \tAverage Loss:  0.2595914605673438\n",
            "Iteration:  12800 \ts:11.2993 \tAverage Loss:  0.06249903557219111\n",
            "Iteration:  12900 \ts:11.6039 \tAverage Loss:  0.1741819370614639\n",
            "Iteration:  13000 \ts:12.6540 \tAverage Loss:  0.2237053151483708\n",
            "Iteration:  13100 \ts:11.7942 \tAverage Loss:  0.17042645411867258\n",
            "Iteration:  13200 \ts:11.8986 \tAverage Loss:  0.09308514864919182\n",
            "Iteration:  13300 \ts:11.6903 \tAverage Loss:  0.20810974077910754\n",
            "Iteration:  13400 \ts:13.0717 \tAverage Loss:  0.2356528211179543\n",
            "Iteration:  13500 \ts:12.2103 \tAverage Loss:  0.1669425829259467\n",
            "Iteration:  13600 \ts:11.7247 \tAverage Loss:  0.12157003183151392\n",
            "Iteration:  13700 \ts:12.8523 \tAverage Loss:  0.14715800312487454\n",
            "Iteration:  13800 \ts:11.6780 \tAverage Loss:  0.1084081244977963\n",
            "Iteration:  13900 \ts:11.3324 \tAverage Loss:  0.1398077296700121\n",
            "Iteration:  14000 \ts:11.1775 \tAverage Loss:  0.14466066529550492\n",
            "Iteration:  14100 \ts:12.4110 \tAverage Loss:  0.12154282044601249\n",
            "Iteration:  14200 \ts:12.0477 \tAverage Loss:  0.1729972968870261\n",
            "Iteration:  14300 \ts:11.7310 \tAverage Loss:  0.12611084820128213\n",
            "Iteration:  14400 \ts:12.7441 \tAverage Loss:  0.17178849903558524\n",
            "Iteration:  14500 \ts:11.8663 \tAverage Loss:  0.14012121706322284\n",
            "Iteration:  14600 \ts:11.5951 \tAverage Loss:  0.08606720595666253\n",
            "Iteration:  14700 \ts:11.4883 \tAverage Loss:  0.06230061874706141\n",
            "Iteration:  14800 \ts:12.5034 \tAverage Loss:  0.08094937258259705\n",
            "Iteration:  14900 \ts:11.5185 \tAverage Loss:  0.08767738142476751\n",
            "Iteration:  15000 \ts:10.7829 \tAverage Loss:  0.313926548447635\n",
            "Epoch time:  1824.090089559555\n",
            "(1.0::addition(tensor(train(0)),tensor(train(1)),5), {})\n",
            "{addition(tensor(train(0)),tensor(train(1)),5): tensor(0.9706, grad_fn=<SelectBackward0>)}\n"
          ]
        }
      ]
    }
  ]
}